import "dotenv/config";
import { HfInference } from "@huggingface/inference";

const token = process.env.HUGGING_FACE_TOKEN;
const hf = new HfInference(token);
const documents = [
  "databricks-dolly-15k is a corpus of more than 15,000 records generated by thousands of Databricks employees to enable large language models to exhibit the magical interactivity of ChatGPT. Databricks employees were invited to create prompt / response pairs in each of eight different instruction categories, including the seven outlined in the InstructGPT paper, as well as an open-ended free-form category. The contributors were instructed to avoid using information from any source on the web with the exception of Wikipedia (for particular subsets of instruction categories), and explicitly instructed to avoid using generative AI in formulating instructions or responses. Examples of each behavior were provided to motivate the types of questions and instructions appropriate to each category./n Halfway through the data generation process, contributors were given the option of answering questions posed by other contributors. They were asked to rephrase the original question and only select questions they could be reasonably expected to answer correctly./n For certain categories contributors were asked to provide reference texts copied from Wikipedia. Reference text (indicated by the context field in the actual dataset) may contain bracketed Wikipedia citation numbers (e.g. [42]) which we recommend users remove for downstream applications.",
];

async function getAnswer() {
  try {
    const result = await hf.questionAnswering({
      model: "deepset/roberta-base-squad2",
      inputs: {
        question: "What is  databricks-dolly-15k?",
        context: documents[0],
      },
    });

    // Print the result to see the answer
    console.log(result);
  } catch (error) {
    console.error("Error fetching answer:", error);
  }
}

getAnswer();
